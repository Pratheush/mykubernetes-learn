kubernetes scheduling :



6. Scheduling Fundamentals

Scheduler Decision Factors

Resource availability (CPU/memory).

Affinity/anti-affinity (placing pods together or separately).

Taints and Tolerations (control pod placement).


we label pod, node, deployment etc that we create in kubernetes ecosystem for clear understanding that what is this application, what are its labels, what is this node for and what are its labels

example we labeled a node wasm, gpu and xyz now we know that wasm workload wil run here in this node and gpu based workload will run here in this node labeled with gpu .
we can label lots of nodes as gpu or wasm etc.

we can do lots of things on label. we can create policies

Kyverno is a tool we can install in kubernetes using Kyverno we can create policies like that if an object has no label then it will not be created.

authentication, authorization, admission . at admission time policies are checked there after checking this policy that label of the object is not there so object will not be created.

or we can create policy like if there is no label then it will be labeled with any default value or default label name this is called mutating web-hook

mutation means when request comes it checks for something whether its there or not and then we add something our own into the object and then apply it so there with using policy we change it


labels and selectors are key-value pairs defined in metadata section


annotations play big role. we can use annotations in kios testing or pods cidr range or cert manager or when we have to define ingress or when we have to define service mesh


this will show label of the pods
kubectl get pods --show-labels

kubectl run mynginx --image=nginx

kubectl get pods --show-labels

kubectl run demonginx --labels='demo=mynginx' --image=nginx

kubectl run demonginx2 -l="demo=mynginx" --image=nginx

# label is key-value pair and here labeling the pod with key as live and value is mydemonginx
kubectl label pod mynginx live=mydemonginx

kubectl get pods --show-labels

labels and selectors add meaning to the kubernetes object

selectors selecting on the based of labels


deployments and services are labeled and seletected in same way i.e. service is also labeled as and selected as with matching label like deployment.
using nodeselector we can alter scheduling
eg nodeselector :
equity based label
set based labels in, notin, exists




selector:
  matchLabels:
    component: redis
  matchExpressions:
    - {key: tier, operator: In, values: [cache]}
    - {key: environment, operator: NotIn, values: [dev]}


here matchLabels:component redis is equity based label
here under matchExpressions set based labels with key and operator and values set and in operator values can be In, NotIn, exists

key can be anything,

so this is telling  select the pod whose label's key is tier or environment and checks that tier or environment exist, in or notIn the values i.e. cache or dev


we can use multiple Scheduler or descheduler or single Scheduler or default Scheduler




kubectl describe pod

kubectl run mynginx --image=nginx

kubectl run demo2nginx -l="app=testing" --image=nginx

kubectl get pods --show-labels

# label is key-value pair and here labeling the pod with key as live and value is mydemonginx
kubectl label pod mynginx app=testing

kubectl get pods --show-labels

# this will list pod where label app is not nginx
kubectl get pod -l app!=nginx


# list all the resource there you can see short names like for deployment deploy , for pod po etc..
kubectl api-resources

kubectl create deploy demo --image=nginx -n bootcamp

kubectl get deploy --show-labels -n bootcamp

kubectl label deploy <deploy-name> app1=demo1 -n bootcamp

kubectl create ns bootcamp

kubectl create deploy demong --image=nginx --replicas 3 -n bootcamp

kubectl create deploy demong --replicas 3 -n bootcamp --image=nginx

# list all the pods with label in braces i.e. either test or bootcamp. here we used set operator.
kubectl get pods -l 'app in (test,bootcamp)'

kubectl get pods --show-labels

kubectl get pods --show-labels -n bootcamp

kubectl get deploy --show-labels -n bootcamp

# list all the namespaces
kubectl get ns


Namespaces: we deploy resources in namespaces
grouping resources together.
namespaces are like logical entity mainly for grouping resources together


Imagine DeployA with 4 replicas and this deployA will go to NamespaceA
and DeployB with 2 replicas and this deployB will go to NamespaceB
and we have VirtualMachine(V1M) and VirtualMachine(V2M)
and I have deployed an application here.
when DeployA was deployed then two pods in V1M and other two pods in V2M
when DeployB was deployed then one pod in V1M and other pod in V2M
But in deploymentB we mentioned that this will deployed in NamespaceB
and deploymentA we mentioned that this will deployed in NamespaceA
so when scheduler schedules it doesn't know about namespaces. scheduler schedules based on resources (like cpu, memory, space etc) stuff like that.
because nodes doesnot know about namespaces and namespaces cannot exist at two places so namespaces are like logical entity which group resources together
but we can make scheduler aware based on the limitrange, resource-quota and limitrange and resource-quota checked at admission phase

Authorization : which namespace you are deploying and do you have the right permission to do > RBAC


grouping of the resources logically why ?

networking can they still communicate ?
in kubernetes there is a concept without net a pod can communicate with other pod

# we are creating a namespace abc
kubectl create ns abc

# running a pod in default namespace. when -n flag is not mentioned then pod will be created in default namespace
kubectl run nginx --image nginx

# creating and running a pod in abc namespace
kubectl run nginx --image nginx -n abc

# listing all the pods with details like pod created in which node and ip of pod
kubectl get pods -owide

# listing all the pods from abc namespace with node and ip info
kubectl get pods -owide -n abc

# here i am exec into nginx running in default namespace from there i am running curl on pod which is running in abc namespace. this proves that eventhough namespace is different two pods can communicate with other pod.
kubectl exec -it nginx -- curl <ip-of another pod from abc - namespace>

kubectl exec -it -n abc bootcamp-7c8698ff84-5pfwc -- curl 192.168.0.4

SO BY DEFAULT PODS CAN COMMUNICATE WITH EACHOTHER

# listing all namespace
kubectl get ns

# creating dev namespace
kubectl create ns dev

# creating bootcamp namespace
kubectl create ns bootcamp

# creating deployment demo in bootcamp namespace using -n flag
kubectl create deploy demo -n bootcamp --image=nginx

# creating deployment demo in dev namespace using -n flag
kubectl create deploy demo -n dev --image=nginx

# setting current namespace dev from default namespace
kubectl config set-context --current --namespace=dev


# creating example namespace
kubectl create ns example-namespace

cat resourcequota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: example-quota
  namespace: example-namespace
spec:
  hard:
    requests.cpu: "500m" # total amount of CPU that can be requested
    requests.memory: "200Gi" # total amount of memory that can be requested
    limits.cpu: "1" # total amount of CPU limit across all pods
    limits.memory: 400Gi # total amount of memory limit across all pods
    pods: "10" # total number of pods that can be created


# creating resourcequota in example-namespace but before that first create example-namespace
kubectl create -f resourcequota.yaml

kubectl apply -f resourcequota.yaml

kubectl get resourcequota -n example-namespace

kubectl delete -f resourcequota.yaml

# getting all ResourceQuota
kubectl get ResourceQuota -A

cat limitrange.yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: example-limitrange
  namespace: example-namespace
spec:
  limits:
  - type: Pod
    max:
      cpu: "2" # max CPU per Pod
      memory: 2Gi # max memory per Pod
    min:
      cpu: "200m" # min CPU per Pod
      memory: 200Mi # min memory per Pod
  - type: Container
    default:
      cpu: "100m" # default CPU request for any container
      memory: 100Mi # default memory request for any container
    defaultRequest:
      cpu: "100m" # default CPU limit for any container
      memory: 100Mi # default memory limit for any container
    max:
      cpu: "1" # max CPU per Container
      memory: 1Gi # max memory per Container
    min:
      cpu: "100m" # min CPU per Container
      memory: 100Mi # min memory per Container



# creating limitrange
kubectl create -f limitrange.yaml


# this will show ResourceQuota but here we can see what request and limit range are set
kubectl get ResourceQuota -A

kubectl get limitrange -A

cat pod-oversize.yaml
apiVersion: v1
kind: Pod
metadata:
  name: oversized-pod
  namespace: example-namespace
spec:
  containers:
  - name: busybox
    image: busybox
    resources:
      requests:
        memory: "600Mi"
        cpu: "600m"
      limits:
        memory: "600Mi"
        cpu: "600m"

# applying pod oversize i.e. by resourcequota request memory size is 500 but here in this pod-oversize request memory is 600. this will give forbidden error because of that. this was checked at admission phase before creating the pod
kubectl apply -f pod-oversize.yaml


# ERROR BECAUSE LIMIT WE PUT IN example-namespace by resourcequota.yaml
controlplane:~/Kubernetes-hindi-bootcamp/part5$ kubectl apply -f pod-oversize.yaml
Error from server (Forbidden): error when creating "pod-oversize.yaml": pods "oversized-pod" is forbidden: exceeded quota: example-quota, requested: requests.cpu=600m, used: requests.cpu=0, limited: requests.cpu=500m

============================================================================================================================================================================================================================================================================================





kubenodelease namespace is for node heartbeat in kubernetes node periodically indicates controlplane that we are alive node is alive. so node heartbeat is reported earlier it goes to kubesystem now it goes to kubenodelease. there are lease objects which improves scalability and performance of the node heartbeats. this is for node heartbeat. this improves failure-detection and quicker


SCHEDULER PERFORMANCE TUNING :
kube-scheduler is the kubernetes default scheduler. It is responsible for placement of pods on nodes in a cluster. Nodes in a cluster that meet the scheduling requirements of a pod are called feasible nodes for the pod. the scheduler finds the feasible nodes for a pod and then runs a set of functions to score the feasible nodes, picking a node with the highest score among the feasible ones to run the pod. the scheduler then notifies the api-server about this decision in a process called binding.

In a large clusters we can tune the schedulers behaviour balancing scheduling  outcomes between latency and accuracy

setting the threshold i.e. percentageOfNodesToScore we can set how many nodes it checked.
percentageOfNodesToScore how it works ? " just simple one or two line explanation easy to remember"
if percentageOfNodesToScore is 50 then what it means ?



scheduling and binding > Queue > filter > score > binding
Queue : pods line up
filters: done through plugin, predicates , filters to decide where your pod can run. you can have meaningful nodes
score : priorities, the scoring
binding : scheduler updates the pod

suppose there are 10 nodes in a cluster and we have to run pod wasm then for wasm filters nodes for wasm pod suppose 3 nodes are filtered and selected and  then scoring is done suppose if this image is already present in a node scoring is high or if a node is spacious so score is high or taint-tolerations and resource-quota etc based on scoring is done and decided based on ranking of node and after that in binding phase that pod is decided to run on which node


POD SCHEDULING : scheduling gates to mark it don't scheduler
POD SCHEDULING READINESS :

==> POD CREATED ==> EMPTY SCHEDULING GATES ? ==> IF YES ==> POD SCHEDULING READY ==> POD RUNNING
                                             ==> IF NO <==> POD SCHEDULING GATED(IT GETS STUCK AT THIS PHASE)

WE REDUCE LOAD ON SCHEDULER LIKE CLUSTER-AUTOSCALER  SCALING UP NODE IN THAT DURATION IF WE SCHEDULE LOTS OF THINGS AND CLUSTER-AUTOSCALER SCHEDULING IT AND IF RESOURCE IS NOT THERE THEN SCHEDULER KEEP CHECKING IT AND IT GETS STUCK IN LOOP THEN WE CAN DEFINE MUTATING ADMISSION WEB-HOOK POLICY WHERE WE DEFINE WHEN WE ARE CREATING POD WE ADD SCHEDULING GATE AND IMMEDIATELY LIKE SUPPOSE WHEN CLUSTER-AUTOSCALER IS NILL OR ANYTHING ELSE THEN WE WRITE POLICY ACCORDINGLY WHICH IT WILL MUTATE SO THE SCHEDULING GATE IS REMOVED AND AS SOON AS SCHEDULING-GATE IS REMOVED POD GETS SCHEDULED



# SchedulingGates set name saiyam:
cat podschedulereadiness
apiVersion: v1
kind: Pod
metadata:
  name: demmo-pod
spec:
  schedulingGates:
  - name: saiyam
  containers:
  - name: pause
    image: registry.k8s.io/pause:3.6


kubectl apply -f podschedulereadiness

# list pods here you will see pod with status SchedulingGated (what it means?)
kubectl get pods


# remove SchedulingGates with name saiyam.
vi podschedulereadiness


kubectl apply -f podschedulereadiness

# now status of pod is different. this time pod will create and ready
kubectl get pods



Topology Spread > we can define how pods are spread across cluster
we can make fault tolerance of appliation by evenly dividing and  distributing pods using Topology-Spread.

scheduler schedules pods and we are learning how to impact the scheduling like using SchedulingGates etc
what else we can use to schedules ??

example : we have a cluster and it has three nodes and these nodes are in different zones so node1 in zoneA and node2 in zoneB and node3 in zoneC. our application is of 3 replicas and we want to make our application fault-tolerant so each pod run into different nodes at different zones and when we scale up our application then each pods scale up and run into different nodes at different zones again meaning we want equal distribution spread so this way we can make our application fault-tolerant in kubernetes cluster

we can use Topology-Spread by mentioning Topology in workload


maxSkew : degree to which pods can be evenly distributed

topologyKey => key of node labels

whenUnsatisfiable > schedule anyway, DoNotSchedule
label Selector > find matching Pods

cat topology.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-app
spec:
  replicas: 4
  selector:
    matchLabels:
      app: demo-app
  template:
    metadata:
      labels:
        app: demo-app
    spec:
      containers:
      - name: app-container
        image: nginx
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: "kubernetes.io/hostname"
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: demo-app

maxSkew must be Integer here maxSkew is 1 means when next pod is going to run then it will go to next node thus one pod in each node going to run.
maxSkew describes the degree to which Pods may be unevenly distributed. must specify this field and number must be greater than zero.

topologyKey we define node label

whenUnsatisfiable: DoNotSchedule, Schedule Anyway. this whenUnsatisfiable tells if this Topology doesn't match then what should be done

labelSelector : finding matching pods

# use kubernetes.io/hostname key and check kubernetes.io/hostname what is the value you will see controlplane based on this topologyKey i.e. kubernetes.io/hostname value i.e. controlplane set or run pod in this node controlplane and checks again since maxSkew is 1 so one pod is set in controlplane so uncertainity can be for one and one more node is there so another pod is set in another node i.e. node01 otherwise scheduler will not schedule since whenUnsatisfiable value is set for DoNotSchedule
kubectl get nodes --show-labels

# topolgy constraint
kubectl apply -f topology.yaml

kubectl get pods

# you will see 4 pods created and evenly distributed i.e. 2 pods per node as per Topology-Spread
kubectl get pods -owide

kubectl get nodes

kubectl get nodes -owide

# scaling deployment demo-app from replicas 4 to 6. since Topology-Spread says evenly distributed
kubectl scale deploy demo-app --replicas 6

# using cordon we are disabling scheduling for the node controlplane
# suppose there is some problem on the node and we don't want any new workload comes to the node so we can cordon node. that way node will not be in ready status so that new pod can run on the node.
kubectl cordon controlplane

kubectl get nodes

# scaling up replicas to 7
kubectl scale  deploy demo-app --replicas 7


kubectl get pods

kubectl scale  deploy demo-app --replicas 8

kubectl get pods -owide

kubectl uncordon controlplane

kubectl get pods -owide




what is topologySpreadConstraints ? how topologySpreadConstraints works and what are the options in it ?


priorityclass is 32bit Integer higher the value higher the priority.

priorityclass used for critical apps



kubectl get priorityclass -A

system-cluster-critical and system-node-critical already exist with higher value. these priorityclass are for system level component i.e. kubernetes components

EXAMPLE : suppose there are four nodes and node01 has 4 pods and node02 has 5 pods and node03 has 3 pods and node04 has 5 pods and apps are running on this cluster at normal priority i.e. default priority which means we did not set any priority. now suppose a mission-critical-app has come which is very important to run as soon as possible so now we have to deploy this mission-critical-app but all the resources are full. so where and how we can run this mission-critical-app so there we set priorityclass at mission-critical-app pod . now this priorityclass will evict pods running with low priority.


cat priority_pod.yaml

# this is priorityclass
cat priority.yaml

# setting controlplane unschedulable or schedulingdisabled so that default-scheduler  will not able to schedule pods on controlplane
kubectl cordon controlplane

# creating deployment mynginx with 100 replicas
kubectl create deploy mynginx --image=nginx --replicas=100

# try this first then run above command and see if it sets pending
# kubectl cordon controlplane

kubectl get pods

# scaling up
kubectl scale deploy mynginx --replicas 110

# checking pods are pending
kubectl get pods

kubectl describe pods

kubectl get po | grep Pen

# look for warning : warning FailedScheduling 27s default-scheduler 0/2 nodes are available : 1 too many pods, 1 node(s) were unschedulable. preemption: 0/2 nodes are available: 1 No preemption victims found for incoming pod, 1 Preemption is not helpful for scheduling.
kubectl describe pod mynginx-<value>

# checking how many pods are running and available and unavailable
kubectl get deploy

# scaling down or up mynginx and check for pending if its there go with experiment
kubectl scale deploy mynginx --replicas 140


kubectl apply -f priority.yaml

# this pod is with priorityclass so this pod will run even if the resource are not available and when we scale up this pod then also it will run even if the resources are not available by evicting the low priority pods
kubectl apply -f priority_pod.yaml

# check this pod for priorityClassName: demo-priority. demo-priority is PriorityClass name from priority.yaml
cat priority_pod.yaml


kubectl get pod high-priority-pod


EXPLAIN POD-OVERHEAD USAGE AND USECASES WITH SIMPLE EXAMPLE IN SIMPLE FEW STATEMENTS TO EASY TO REMEMBER ?
Pod Overhead : some runtimes(gviser, kata etc) use more resources for pod operations and we can specify the pod-overhead in RuntimeClass and the Scheduler takes pod-overhead request and pod request both and then make scheduling decision layout that at this node this number of resources are available so scheduler can schedule.

NodeAffinity is used for altering scheduling
Taints & Tolerations is used for altering scheduling
nodeselector for altering scheduling
nodename for altering scheduling

kubectl delete deploy --all

kubectl delete deploy -A

Node Affinity is similar to NodeSelector. where your pods can be scheduled based on labels of Nodes.
in Node Affinity we can specify lots of things. for example we can specify these below fields :
1. required During Scheduling Ignored During Execution > hard (only run Pods on Nodes with xyz)
2. prefered During Scheduling Ignored During Execution > Soft (try to run pods). here in this if node labels changed at Runtime it won't affect the other pods.


defining affinity in yaml file for pod means that we want this pod to go there that means this pod get schedule on such nodes
key: kubernetes.io/e2e-az-name : here kubernetes.io is prefix i.e. what mentioned before /(forward slash) this is not mandatory but good practise

apiVersion: v1
kind: Pod
metadata:
  name: with-node-affinity
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/e2e-az-name  # this Pod can be scheduled on node where this label defined in key here on node
            operator: In                    # since operator is In so values can be within these two defined below.
            values:                       # Pod can be scheduled where this label defined in key here on node with below either of two values
            - e2e-az1
            - e2e-az2
      preferredDuringSchedulingIgnoredDuringExecution:   # if multiple nodes meet above criteria then prefer node matching.
      - weight: 1
        preference:
          matchExpressions:
          - key: another-node-label-key
            operator: In
            values:
            -  another-node-label-value
  containers:
  - name: with-node-affinity
    image: k8s.gcr.io/pause:2.0


so here requiredDuringSchedulingIgnoredDuringExecution: this is telling run this pod and at the time of scheduling this should be the label that defined in matchExpressions key and values should be either of two values specified i.e. e2e-az1 or e2e-az2.
preferredDuringSchedulingIgnoredDuringExecution:  this is telling that if multiple nodes meet above criteria i.e. defined in requiredDuringSchedulingIgnoredDuringExecution  then prefer node matching based on specified matchExpressions inside preferredDuringSchedulingIgnoredDuringExecution then prefer on node label specified inside key i.e. another-node-label-key and values i.e. another-node-label-value.



kubectl cordon controlplane

cat nodeaffinity

apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: mycontainer
    image: nginx
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: "topology.kubernetes.io/region"
            operator: In
            values:
            - "us-east-1"
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: "disktype"
            operator: In
            values:
            - "ssd"

kubectl apply -f nodeaffinity

# if pod is showing pending in status (mypod here)
kubectl get pods

# this will give error as there is no node with the specified label in nodeaffinity
kubectl describe pod mypod

kubectl get nodes

kubectl label node node01 topology.kubernetes.io/region=us-east-1

kubectl get nodes --show-label

kubectl describe pod mypod

kubectl get pods

kubectl label node controlplane topology.kubernetes.io/region=us-east-1

kubectl label node controlplane disktype=ssd

kubectl uncordon controlplane

kubectl delete -f nodeaffinity

kubectl apply -f nodeaffinity



Node Affinity is a property of Pods that attracts them to a set of nodes(either as a preference or a hard requirement).
Taints are the opposite - they allow a node to repel a set of pods.


 A cluster with controlplane and three nodes and one node is setup with taint(foo=bar:NoSchedule). scheduler schedules pod and checks taints i.e. foo=bar:NoSchedule here a POD with toleration i.e. Key:"foo", operator:"Equal" and value:"bar" and effect:"NoSchedule" will schedule on this node which is tainted with foo=bar:NoSchedule.


 operator: Equal/Exist/NoValueReq.
 effects: NoSchedule/PreferNoSchedule(if pod is not scheduled on any node then schedule here on this node)/NoExecute

 if node is tainted with NoExecute Effect then suppose if a node has two running pods and there is no toleration and suppose node is tainted with Effect NoExecute then pod running from earlier will be evicted if tainted and only matching toleration specified pod will run at the node.

USECASES:
1. Dedicated Nodes
2. Special Hardware
3. Taint Based Evictions -> No Execute.


cat toleration.yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-tolerations
spec:
  containers:
  - name: nginx
    image: nginx
  tolerations:
  - key: "app"
    operator: "Equal"
    value: "demo"
    effect: "NoSchedule"

kubectl apply -f toleration.yaml

kubectl get pods

kubectl delete -f toleration.yaml

# till now there is no taint on our nodes so lets taint our node01
kubectl taint nodes node01 app=demo:NoSchedule

kubectl get nodes

kubectl get pods

kubectl cordon controlplane

kubectl run abc --image=abc

kubectl get nodes

# only node01 where pod can schedule since controlplane is cordoned
# but node01 is tainted  so pod with toleration matching to node01 taint will run
kubectl get pods

kubectl describe pod

# node01 is tainted with app=demo:NoSchedule so a matching pod with toleration will run on node01
kubectl apply -f toleration.yaml

kubectl get pods

# here node is tainted with effect NoExecute so earlier running pod will evvict and pod with toleration where effect does not matchup
kubectl taint nodes node01 app=demo:NoExecute

kubectl get pods

kubectl get pods -owide



kubectl run nginx --image=nginx --dry-run=client -oyaml


vi pod

apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: nginx
  name: nginx
spec:
  nodeName: node01
  containers:
  - image: nginx
    name: nginx
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}

since we add nodeName in yaml file of pod and specify on which node pod will run this will bypass scheduler
add nodeName in spec section with value as node01

kubectl apply -f po

kubectl get pods -owide

nodeselector by yourself


priority-class




go through the statements given and make corrections and edit and suggest with simple language to easy to understand and remember about the concept RESOURCE REQUEST LIMIT in kubernetes with examples and easy explanations to remember in simple language






























































